# -*- coding: utf-8 -*-
import streamlit as st
import os
import pandas as pd
from langchain.document_loaders import PyPDFLoader, Docx2txtLoader, TextLoader
from langchain.indexes import VectorstoreIndexCreator
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.docstore.document import Document

# Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© chromadb
try:
    from langchain.vectorstores import Chroma
except ImportError:
    st.warning("Ø¬Ø§Ø±Ù ØªØ«Ø¨ÙŠØª Ø­Ø²Ù… Ø¥Ø¶Ø§ÙÙŠØ©... (Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø¯Ù‚Ø§Ø¦Ù‚)")
    os.system("pip install chromadb sentence-transformers")
    from langchain.vectorstores import Chroma

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
st.set_page_config(page_title="Ù†Ø¸Ø§Ù… Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø³Ø§Ø¨Ù‚Ø©", layout="wide")
st.title("ğŸ§  Ù†Ø¸Ø§Ù… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù† Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø³Ø§Ø¨Ù‚Ø©")

# 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª
uploaded_file = st.file_uploader(
    "Ø±ÙØ¹ ÙˆØ«ÙŠÙ‚Ø© Ø§Ù„Ù…Ø³Ø§Ø¨Ù‚Ø© (PDF, DOCX, TXT, XLSX)", 
    type=['pdf', 'docx', 'txt', 'xlsx'],
    accept_multiple_files=False
)

# 2. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª (Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Excel)
def process_file(uploaded_file):
    try:
        temp_file = f"temp_{uploaded_file.name}"
        with open(temp_file, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        if uploaded_file.name.endswith('.pdf'):
            loader = PyPDFLoader(temp_file)
            documents = loader.load()
        elif uploaded_file.name.endswith('.docx'):
            loader = Docx2txtLoader(temp_file)
            documents = loader.load()
        elif uploaded_file.name.endswith('.txt'):
            loader = TextLoader(temp_file, encoding='utf-8')
            documents = loader.load()
        elif uploaded_file.name.endswith('.xlsx'):
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„ÙØ§Øª Excel
            df = pd.read_excel(temp_file)
            documents = []
            for index, row in df.iterrows():
                content = "\n".join([f"{col}: {val}" for col, val in row.items()])
                documents.append(Document(page_content=content, metadata={"source": "excel"}))
            loader = None  # Ù„Ø§ ÙŠÙˆØ¬Ø¯ loader Ù„Ù…Ù„ÙØ§Øª Excel
        else:
            st.error("Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…")
            return None, None
        
        os.remove(temp_file)  # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
        return documents, loader
    
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {str(e)}")
        return None, None

# 3. Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª
if uploaded_file:
    documents, loader = process_file(uploaded_file)
    
    if documents:  # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª
        st.success(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­! (Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª: {len(documents)})")
        
        # Ø¥Ù†Ø´Ø§Ø¡ ÙÙ‡Ø±Ø³ Ù„Ù„Ø¨Ø­Ø«
        try:
            if loader:  # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ loader (Ù„Ù„Ù…Ù„ÙØ§Øª ØºÙŠØ± Excel)
                index = VectorstoreIndexCreator(
                    embedding=HuggingFaceEmbeddings(),
                    text_splitter=RecursiveCharacterTextSplitter(
                        chunk_size=1000,
                        chunk_overlap=200
                    )
                ).from_loaders([loader])
                retriever = index.vectorstore.as_retriever()
            else:  # Ù„Ù…Ù„ÙØ§Øª Excel
                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=1000,
                    chunk_overlap=200
                )
                texts = text_splitter.split_documents(documents)
                embeddings = HuggingFaceEmbeddings()
                vectorstore = Chroma.from_documents(texts, embeddings)
                retriever = vectorstore.as_retriever()
            
            # ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
            st.divider()
            question = st.text_input("Ø§Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø¹Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø¨Ù‚Ø©:")
            
            if question:
                from langchain.chains import RetrievalQA
                from langchain.llms import OpenAI
                
                # Ø§Ø³ØªØ¨Ø¯Ù„ Ù‡Ø°Ø§ Ø¨Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ (WatsonX Ø£Ùˆ ØºÙŠØ±Ù‡)
                llm = OpenAI(temperature=0)
                
                qa = RetrievalQA.from_chain_type(
                    llm=llm,
                    chain_type="stuff",
                    retriever=retriever
                )
                result = qa({"query": question})
                st.subheader("Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:")
                st.write(result["result"])
                
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø©: {str(e)}")

# 4. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
with st.sidebar:
    st.header("Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    st.info("""
    **ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:**
    1. Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ù…Ø³Ø§Ø¨Ù‚Ø© (PDF, Word, Excel, Text)
    2. Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ ÙÙŠ Ù…Ø±Ø¨Ø¹ Ø§Ù„Ù†Øµ
    3. Ø§Ø¶ØºØ· Enter Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
    """)
    st.warning("Ù…Ù„Ø§Ø­Ø¸Ø©: Ù„Ù…Ù„ÙØ§Øª ExcelØŒ ÙŠØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙÙˆÙ ÙƒØ¨ÙŠØ§Ù†Ø§Øª Ù†ØµÙŠØ©")
