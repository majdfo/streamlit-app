# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import os
import tempfile
from langchain.llms import OpenAI
from langchain.chains import LLMChain, RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.document_loaders import (
    PyPDFLoader,
    Docx2txtLoader,
    TextLoader,
    CSVLoader,
    UnstructuredExcelLoader
)
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.docstore.document import Document

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
st.set_page_config(page_title="ğŸ§  Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", layout="wide")
st.title("ğŸ“Š Ù†Ø¸Ø§Ù… ÙÙ‡Ù… ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°ÙƒÙŠ")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙØªØ§Ø­ API
with st.sidebar:
    st.subheader("Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©")
    api_key = st.text_input("Ø£Ø¯Ø®Ù„ Ù…ÙØªØ§Ø­ OpenAI API", type="password", key="api_key")
    if api_key:
        os.environ['OPENAI_API_KEY'] = api_key
        st.success("ØªÙ… Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨Ù†Ø¬Ø§Ø­!")
    
    st.markdown("---")
    st.subheader("ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    uploaded_file = st.file_uploader(
        "Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù (Excel, PDF, Word, CSV, TXT)",
        type=['xlsx', 'xls', 'csv', 'pdf', 'docx', 'txt']
    )

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ù„ÙØ§Øª
def process_file(file):
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.name)[1]) as tmp_file:
            tmp_file.write(file.getvalue())
            tmp_path = tmp_file.name
        
        if file.name.endswith(('.xlsx', '.xls')):
            loader = UnstructuredExcelLoader(tmp_path)
        elif file.name.endswith('.csv'):
            loader = CSVLoader(tmp_path, encoding='utf-8')
        elif file.name.endswith('.pdf'):
            loader = PyPDFLoader(tmp_path)
        elif file.name.endswith('.docx'):
            loader = Docx2txtLoader(tmp_path)
        elif file.name.endswith('.txt'):
            loader = TextLoader(tmp_path, encoding='utf-8')
        else:
            st.error("Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…")
            return None
        
        data = loader.load()
        return data
    
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {str(e)}")
        return None
    finally:
        if os.path.exists(tmp_path):
            os.unlink(tmp_path)

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ÙˆØ«Ø§Ø¦Ù‚
def create_documents(data):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=["\n\n", "\n", "Û”", " ", ""]
    )
    return text_splitter.split_documents(data)

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„
if uploaded_file and 'api_key' in st.session_state:
    data = process_file(uploaded_file)
    
    if data:
        st.success(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(data)} Ù…Ø³ØªÙ†Ø¯/ØµÙ Ø¨Ù†Ø¬Ø§Ø­!")
        
        # Ø¥Ù†Ø´Ø§Ø¡ ÙÙ‡Ø±Ø³ Ø§Ù„Ø¨Ø­Ø«
        documents = create_documents(data)
        embeddings = HuggingFaceEmbeddings(model_name="uer/sbert-base-arabic-light")
        db = FAISS.from_documents(documents, embeddings)
        st.session_state.db = db
        
        # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        with st.expander("Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
            if uploaded_file.name.endswith(('.xlsx', '.xls', '.csv')):
                try:
                    if uploaded_file.name.endswith('.csv'):
                        df = pd.read_csv(uploaded_file)
                    else:
                        df = pd.read_excel(uploaded_file)
                    st.dataframe(df.head(3))
                except:
                    st.write(documents[:1])
            else:
                st.write(documents[:1])

# Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø°ÙƒÙŠØ©
if 'db' in st.session_state and 'api_key' in st.session_state:
    st.markdown("---")
    st.subheader("Ø§Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„Ùƒ")
    
    question = st.text_area("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§ (ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ø§Ù…ÙŠØ©)", height=100)
    
    if question:
        try:
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            docs = st.session_state.db.similarity_search(question, k=3)
            context = "\n\n".join([doc.page_content for doc in docs])
            
            # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„
            is_general_question = any(word in question for word in [
                "Ø´Ùˆ", "Ù„ÙŠØ´", "ÙƒÙŠÙ", "Ù„Ù…Ø§", "Ø¹Ù„Ø§Ø¬", "Ø³Ø¨Ø¨", "Ø±Ø£ÙŠÙƒ"
            ])
            
            # ØªØµÙ…ÙŠÙ… Prompt Ø°ÙƒÙŠ
            prompt_template = PromptTemplate(
                input_variables=["context", "question"],
                template="""
                Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:
                {context}
                
                Ø§Ù„Ø³Ø¤Ø§Ù„: {question}
                
                Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
                1. ÙÙ‡Ù… Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø¯Ù‚Ø© (Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù† Ø¹Ø§Ù…ÙŠØ§Ù‹)
                2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¥Ø¬Ø§Ø¨Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                3. Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø­Ø¯Ø¯Ø©ØŒ Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ø§Ù…Ø©
                4. Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ø¶Ø­Ø©
                
                Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
                """
            )
            
            llm = OpenAI(temperature=0.6, max_tokens=800)
            qa_chain = LLMChain(llm=llm, prompt=prompt_template)
            response = qa_chain.run(context=context, question=question)
            
            st.markdown("---")
            st.subheader("Ø§Ù„Ù†ØªÙŠØ¬Ø©:")
            st.write(response)
            
            with st.expander("Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©"):
                st.write(docs)
                
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}")

# Ø¥Ø¶Ø§ÙØ© Ø£Ù…Ø«Ù„Ø© ØªÙˆØ¶ÙŠØ­ÙŠØ©
with st.expander("Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© ÙŠÙ…ÙƒÙ† Ø·Ø±Ø­Ù‡Ø§"):
    st.markdown("""
    **Ù„Ø¨ÙŠØ§Ù†Ø§Øª Excel/CSV:**
    - "Ø´Ùˆ Ø£Ø¹Ù„Ù‰ Ø±Ø§ØªØ¨ ÙÙŠ Ø§Ù„Ø´Ø±ÙƒØ©ØŸ"
    - "ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ† ÙÙŠ Ù‚Ø³Ù… Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§ØªØŸ"
    - "Ù„Ù…Ø§ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ù†Ø²Ù„Øª ÙÙŠ ÙŠÙ†Ø§ÙŠØ±ØŸ"
    
    **Ù„Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù†ØµÙŠØ©:**
    - "Ø´Ùˆ Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø¥Ø¯Ø§Ø±ÙŠØ©ØŸ"
    - "Ø¥ÙŠØ´ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø© Ù„Ù„Ø¨Ø·Ø§Ù„Ø©ØŸ"
    - "Ø¹Ù†Ø¯ÙŠ Ù…Ø´ÙƒÙ„Ø© Ù…Ø¹ Ø§Ù„Ù…Ø¯ÙŠØ±ØŒ Ø´Ùˆ Ø§Ù„Ø­Ù„ØŸ"
    
    **Ø£Ø³Ø¦Ù„Ø© Ø¹Ø§Ù…Ø©:**
    - "Ø´Ùˆ Ø£ÙØ¶Ù„ Ø·Ø±ÙŠÙ‚Ø© Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø£Ø·ÙØ§Ù„ØŸ"
    - "ÙƒÙŠÙ Ø£ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø¶ØºÙˆØ· Ø§Ù„Ø¹Ù…Ù„ØŸ"
    """)
